# Changelog

Tutte le modifiche significative a questo progetto saranno documentate in questo file.

Il formato Ã¨ basato su [Keep a Changelog](https://keepachangelog.com/it/1.0.0/),
e questo progetto aderisce al [Semantic Versioning](https://semver.org/lang/it/).

## [1.0.0] - 2025-10-21

### Aggiunto
- ðŸŽ‰ Release iniziale dell'addon Llama.cpp per Home Assistant
- âœ… Integrazione completa di llama.cpp in container Docker
- âœ… Build multi-stage ottimizzato per dimensioni ridotte
- âœ… Server API OpenAI-compatible sulla porta 8080
- âœ… Servizio Home Assistant custom sulla porta 5000
- âœ… Supporto per chat singolo tramite `/api/chat`
- âœ… Supporto per conversazioni multi-turno con gestione sessioni
- âœ… Endpoint per avvio, gestione e eliminazione conversazioni
- âœ… Download automatico modelli GGUF da Hugging Face
- âœ… Configurazione tramite config.yaml di Home Assistant
- âœ… Supporto per modelli configurabili dall'utente
- âœ… Parametri configurabili: context size, threads, GPU layers, parallel requests
- âœ… Health check endpoints per monitoring
- âœ… Logging configurabile con livelli debug/info/warning/error
- âœ… Traduzioni italiane e inglesi per l'interfaccia HA
- âœ… Documentazione completa con README dettagliato
- âœ… Test suite completa con dati reali (no mock)
- âœ… Script di esempi Python per integrazione
- âœ… TODO list per roadmap futura
- âœ… License MIT

### Caratteristiche Tecniche
- Docker multi-stage build per ottimizzazione
- Compilazione llama.cpp da sorgente con supporto CUDA opzionale
- Flask API server per servizi Home Assistant
- Requests library per chiamate HTTP
- CORS abilitato per cross-origin requests
- Storage in-memory per sessioni conversazione
- Timeout configurabili per operazioni LLM
- Error handling robusto con messaggi descrittivi
- Validazione input su tutti gli endpoint

### Modelli Supportati
- âœ… Gemma 3 1B (default)
- âœ… Phi-3 Mini
- âœ… LLaMA 3.2 3B
- âœ… LLaMA 3.1 8B
- âœ… Qualsiasi modello GGUF compatibile

### API Endpoints
- `POST /api/chat` - Chat singolo
- `POST /api/conversation/start` - Avvia conversazione
- `POST /api/conversation/<id>/message` - Invia messaggio
- `GET /api/conversation/<id>/history` - Storia conversazione
- `DELETE /api/conversation/<id>` - Elimina conversazione
- `GET /api/conversations` - Lista conversazioni
- `GET /api/health` - Health check
- `GET /api/models` - Info modelli
- `POST /v1/chat/completions` - OpenAI compatible
- `GET /v1/models` - OpenAI models
- `GET /health` - Llama.cpp health

### Documentazione
- README.md con guida completa
- Esempi di utilizzo con Python
- Integrazioni con automazioni Home Assistant
- Guide per configurazione modelli
- Troubleshooting e best practices
- Performance benchmarks

### Test
- Test suite con unittest
- Health checks per server
- Test API chat singolo
- Test conversazioni multi-turno
- Test compatibilitÃ  OpenAI
- Test performance e limiti
- Tutti i test con dati reali

## [Unreleased]

### Pianificato per v1.1.0
- [ ] Integrazione nativa con Conversation Agent HA
- [ ] Dashboard Lovelace per UI chat
- [ ] Supporto WebSocket per streaming
- [ ] Cache intelligente risposte
- [ ] Metrics Prometheus
- [ ] Build ARM64 ottimizzata

### Pianificato per v1.2.0
- [ ] Supporto RAG (Retrieval Augmented Generation)
- [ ] Multi-modello con switch dinamico
- [ ] Fine-tuning capabilities
- [ ] Advanced security features

---

## Formato delle Modifiche

### Categorie
- **Aggiunto** - per nuove funzionalitÃ 
- **Modificato** - per cambiamenti a funzionalitÃ  esistenti
- **Deprecato** - per funzionalitÃ  che saranno rimosse
- **Rimosso** - per funzionalitÃ  rimosse
- **Corretto** - per bug fix
- **Sicurezza** - per vulnerabilitÃ  corrette

### Esempio Entry
```markdown
## [X.Y.Z] - YYYY-MM-DD

### Aggiunto
- Nuova funzionalitÃ  XYZ (#123)

### Corretto
- Bug nella funzione ABC (#456)
```

---

Per vedere la differenza tra versioni, usa:
```
git diff v1.0.0..v1.1.0
```
