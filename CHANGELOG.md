# Changelog

Tutte le modifiche significative a questo progetto saranno documentate in questo file.

Il formato Ã¨ basato su [Keep a Changelog](https://keepachangelog.com/it/1.0.0/),
e questo progetto aderisce al [Semantic Versioning](https://semver.org/lang/it/).

## [1.0.4] - 2025-01-15

### ğŸ†• Aggiunto - Home Assistant Integration
- ğŸ  **Integrazione completa con Home Assistant**
  - Nuovo modulo `ha_integration.py` con client per Supervisor API
  - Classe `HomeAssistantClient` per accesso a entitÃ , servizi, configurazione
  - Classe `HAContextBuilder` per costruzione contesto intelligente per LLM
  
- ğŸ“¡ **Nuovi endpoint API**:
  - `GET /api/ha/entities` - Lista tutte le entitÃ  con filtro per dominio
  - `GET /api/ha/entity/{id}` - Dettagli entitÃ  specifica
  - `GET /api/ha/services` - Lista tutti i servizi disponibili
  - `POST /api/ha/service/call` - Chiamata diretta servizi HA
  - `GET /api/ha/config` - Configurazione sistema Home Assistant
  - `GET /api/ha/context` - Contesto formattato per LLM
  
- ğŸ§  **Context-aware Chat**:
  - Endpoint `/api/chat` ora supporta parametri per contesto HA
  - `include_entities`: Include stato entitÃ  nel prompt
  - `include_services`: Include servizi disponibili nel prompt
  - `entity_domains`: Filtra entitÃ  per domini specifici (light, switch, etc.)
  - LLM ora ha visibilitÃ  completa dello stato della smart home
  
- ğŸ“š **Documentazione**:
  - Nuovo file `HA_INTEGRATION.md` con guida completa integrazione
  - Esempi API con Python, JavaScript, cURL
  - Documentazione architettura e context injection
  - Script di test `test_ha_integration.py`
  
- âš™ï¸ **Configurazione**:
  - Porta 5000 esposta per API integrazione HA
  - Flag `hassio_api: true` per accesso Supervisor API
  - Token `SUPERVISOR_TOKEN` automaticamente disponibile

### Modificato
- ğŸ“ README aggiornato con sezione integrazione HA
- ğŸ“ TODO aggiornato con nuove feature implementate e roadmap
- ğŸ”§ `config.yaml` aggiornato alla versione 1.0.4
- ğŸ”§ Descrizione addon evidenzia integrazione HA

### Prossime feature pianificate
- Function calling automatico per esecuzione servizi HA
- Natural language â†’ service execution (es: "turn on lights")
- Webhook support per aggiornamenti real-time
- Entity history analysis
- Automation suggestions basate su pattern

---

## [1.0.3] - 2025-01-14

### Risolto
- ğŸ› **Fix crash llama-server**: Rimossi flag non supportati
  - `--log-format`, `--metrics`, `--cont-batching`, `--flash-attn`
  - Server ora avvia correttamente senza crash loop
  
### Modificato
- âš¡ Comando llama-server semplificato in `run.sh`
- ğŸ“ Documentazione aggiornata

---

## [1.0.2] - 2025-01-14

### Risolto
- ğŸ› **Fix build Alpine Linux**: Dockerfile riscritto per Alpine
  - Sostituito `apt-get` con `apk` (Alpine package manager)
  - Build statica con `-DGGML_STATIC=ON`
  - CompatibilitÃ  con immagini base Home Assistant (Alpine 3.18)
  
### Modificato
- ğŸ—ï¸ Dockerfile completamente riscritto per Alpine Linux
- ğŸ“¦ Builder stage usa `alpine:3.18` invece di Ubuntu

---

## [1.0.1] - 2025-01-13

### Risolto
- ğŸ› **Fix errore 403**: Commentata riga `image:` in config.yaml
  - Forza build locale da Dockerfile
  - Risolve impossibilitÃ  di scaricare immagine da ghcr.io
  
### Modificato
- ğŸ”§ `config.yaml`: Riga `image:` commentata per build locale
- ğŸ“ Documentazione aggiornata con note sul build

---

## [1.0.0] - 2025-01-10

### Aggiunto
- ğŸ‰ Release iniziale dell'addon Llama.cpp per Home Assistant
- âœ… Integrazione completa di llama.cpp in container Docker
- âœ… Build multi-stage ottimizzato per dimensioni ridotte
- âœ… Server API OpenAI-compatible sulla porta 8080
- âœ… Servizio Home Assistant custom sulla porta 5000
- âœ… Supporto per chat singolo tramite `/api/chat`
- âœ… Supporto per conversazioni multi-turno con gestione sessioni
- âœ… Endpoint per avvio, gestione e eliminazione conversazioni
- âœ… Download automatico modelli GGUF da Hugging Face
- âœ… Configurazione tramite config.yaml di Home Assistant
- âœ… Supporto per modelli configurabili dall'utente
- âœ… Parametri configurabili: context size, threads, GPU layers, parallel requests
- âœ… Health check endpoints per monitoring
- âœ… Logging configurabile con livelli debug/info/warning/error
- âœ… Traduzioni italiane e inglesi per l'interfaccia HA
- âœ… Documentazione completa con README dettagliato
- âœ… Test suite completa con dati reali (no mock)
- âœ… Script di esempi Python per integrazione
- âœ… TODO list per roadmap futura
- âœ… License MIT

### Caratteristiche Tecniche
- Docker multi-stage build per ottimizzazione
- Compilazione llama.cpp da sorgente con supporto CUDA opzionale
- Flask API server per servizi Home Assistant
- Requests library per chiamate HTTP
- CORS abilitato per cross-origin requests
- Storage in-memory per sessioni conversazione
- Timeout configurabili per operazioni LLM
- Error handling robusto con messaggi descrittivi
- Validazione input su tutti gli endpoint

### Modelli Supportati
- âœ… Gemma 3 1B (default)
- âœ… Phi-3 Mini
- âœ… LLaMA 3.2 3B
- âœ… LLaMA 3.1 8B
- âœ… Qualsiasi modello GGUF compatibile

### API Endpoints
- `POST /api/chat` - Chat singolo
- `POST /api/conversation/start` - Avvia conversazione
- `POST /api/conversation/<id>/message` - Invia messaggio
- `GET /api/conversation/<id>/history` - Storia conversazione
- `DELETE /api/conversation/<id>` - Elimina conversazione
- `GET /api/conversations` - Lista conversazioni
- `GET /api/health` - Health check
- `GET /api/models` - Info modelli
- `POST /v1/chat/completions` - OpenAI compatible
- `GET /v1/models` - OpenAI models
- `GET /health` - Llama.cpp health

### Documentazione
- README.md con guida completa
- Esempi di utilizzo con Python
- Integrazioni con automazioni Home Assistant
- Guide per configurazione modelli
- Troubleshooting e best practices
- Performance benchmarks

### Test
- Test suite con unittest
- Health checks per server
- Test API chat singolo
- Test conversazioni multi-turno
- Test compatibilitÃ  OpenAI
- Test performance e limiti
- Tutti i test con dati reali

## [Unreleased]

### Pianificato per v1.1.0
- [ ] Integrazione nativa con Conversation Agent HA
- [ ] Dashboard Lovelace per UI chat
- [ ] Supporto WebSocket per streaming
- [ ] Cache intelligente risposte
- [ ] Metrics Prometheus
- [ ] Build ARM64 ottimizzata

### Pianificato per v1.2.0
- [ ] Supporto RAG (Retrieval Augmented Generation)
- [ ] Multi-modello con switch dinamico
- [ ] Fine-tuning capabilities
- [ ] Advanced security features

---

## Formato delle Modifiche

### Categorie
- **Aggiunto** - per nuove funzionalitÃ 
- **Modificato** - per cambiamenti a funzionalitÃ  esistenti
- **Deprecato** - per funzionalitÃ  che saranno rimosse
- **Rimosso** - per funzionalitÃ  rimosse
- **Corretto** - per bug fix
- **Sicurezza** - per vulnerabilitÃ  corrette

### Esempio Entry
```markdown
## [X.Y.Z] - YYYY-MM-DD

### Aggiunto
- Nuova funzionalitÃ  XYZ (#123)

### Corretto
- Bug nella funzione ABC (#456)
```

---

Per vedere la differenza tra versioni, usa:
```
git diff v1.0.0..v1.1.0
```
